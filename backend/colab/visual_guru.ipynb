{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# =========================================================\n",
                "# MUKTHI GURU: FINAL VISUALIZATION EDITION (3D + Interactive)\n",
                "# =========================================================\n",
                "# Run this notebook in Google Colab (with GPU Runtime)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ---------------------------------------------------------\n",
                "# 1. INSTALLATION & SETUP\n",
                "# ---------------------------------------------------------\n",
                "print(\"‚è≥ Installing dependencies... (Allow ~2-3 mins)\")\n",
                "\n",
                "# A. Install System Dependencies\n",
                "!apt-get update -qq && apt-get install -y nodejs ffmpeg > /dev/null\n",
                "\n",
                "# B. Install Python Libraries (Added plotly for 3D)\n",
                "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\" --quiet\n",
                "!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes --quiet\n",
                "!pip install -q qdrant-client sentence-transformers youtube-transcript-api yt-dlp faster-whisper matplotlib scikit-learn pandas plotly\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ---------------------------------------------------------\n",
                "# 2. DRIVE PERSISTENCE\n",
                "# ---------------------------------------------------------\n",
                "try:\n",
                "    from google.colab import drive\n",
                "    import os\n",
                "\n",
                "    drive.mount('/content/drive', force_remount=True)\n",
                "    QDRANT_PATH = \"/content/drive/MyDrive/mukthi_qdrant_visual_v1\" \n",
                "except ImportError:\n",
                "    print(\"‚ö†Ô∏è Google Colab not detected. Skipping Drive mount.\")\n",
                "    QDRANT_PATH = \"./mukthi_qdrant_visual_v1\"\n",
                "\n",
                "if not os.path.exists(QDRANT_PATH):\n",
                "    os.makedirs(QDRANT_PATH, exist_ok=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ---------------------------------------------------------\n",
                "# 3. IMPORTS\n",
                "# ---------------------------------------------------------\n",
                "import torch\n",
                "import time\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from sklearn.decomposition import PCA\n",
                "import plotly.express as px  # THE 3D WIZARD\n",
                "\n",
                "try:\n",
                "    from unsloth import FastLanguageModel\n",
                "except ImportError:\n",
                "    print(\"‚ö†Ô∏è 'unsloth' package not found. Model loading will fail.\")\n",
                "    FastLanguageModel = None # Stub\n",
                "\n",
                "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
                "from qdrant_client import QdrantClient\n",
                "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
                "from faster_whisper import WhisperModel\n",
                "from youtube_transcript_api import YouTubeTranscriptApi as YTApi\n",
                "import yt_dlp\n",
                "\n",
                "# Force GPU Usage\n",
                "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"üöÄ Acceleration Status: {DEVICE.upper()}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ---------------------------------------------------------\n",
                "# 4. LOAD MODELS\n",
                "# ---------------------------------------------------------\n",
                "\n",
                "# A. Load Llama-3 (Unsloth 4-bit)\n",
                "print(\"\\nü¶ô Loading Llama-3 8B (4-bit)...\")\n",
                "if FastLanguageModel:\n",
                "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
                "        model_name = \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
                "        max_seq_length = 2048,\n",
                "        dtype = None,\n",
                "        load_in_4bit = True,\n",
                "    )\n",
                "    FastLanguageModel.for_inference(model)\n",
                "else:\n",
                "    print(\"‚ùå FastLanguageModel/Unsloth not available.\")\n",
                "    model, tokenizer = None, None\n",
                "\n",
                "# B. Load SOTA Retrieval Models\n",
                "print(\"üß† Loading BGE Embeddings & Reranker...\")\n",
                "embed_model = SentenceTransformer(\"BAAI/bge-base-en-v1.5\", device=DEVICE)\n",
                "reranker = CrossEncoder(\"BAAI/bge-reranker-base\", device=DEVICE)\n",
                "\n",
                "# C. Load Whisper\n",
                "whisper_model = WhisperModel(\"base\", device=DEVICE, compute_type=\"float16\")\n",
                "\n",
                "# D. Connect to Qdrant\n",
                "print(f\"üóÑÔ∏è Connected to Knowledge Base at: {QDRANT_PATH}\")\n",
                "client = QdrantClient(path=QDRANT_PATH)\n",
                "\n",
                "COLLECTION_NAME = \"mukthi_teachings_visual\"\n",
                "\n",
                "# Ensure Collection Exists\n",
                "collections = client.get_collections().collections\n",
                "if COLLECTION_NAME not in [c.name for c in collections]:\n",
                "    client.create_collection(\n",
                "        collection_name=COLLECTION_NAME,\n",
                "        vectors_config=VectorParams(size=768, distance=Distance.COSINE),\n",
                "    )\n",
                "    print(f\"‚úÖ Created new collection '{COLLECTION_NAME}'.\")\n",
                "else:\n",
                "    print(f\"‚úÖ Loaded existing collection '{COLLECTION_NAME}'.\")\n",
                "\n",
                "print(\"‚úÖ System Fully Loaded.\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ---------------------------------------------------------\n",
                "# 5. INGESTION FUNCTIONS\n",
                "# ---------------------------------------------------------\n",
                "\n",
                "def download_audio(url):\n",
                "    audio_file = os.path.join(QDRANT_PATH, \"audio.mp3\")\n",
                "    if os.path.exists(audio_file):\n",
                "        os.remove(audio_file)\n",
                "        \n",
                "    ydl_opts = {\n",
                "        'format': 'bestaudio/best',\n",
                "        'outtmpl': os.path.join(QDRANT_PATH, \"audio\"), \n",
                "        'quiet': True,\n",
                "        'postprocessors': [{'key': 'FFmpegExtractAudio','preferredcodec': 'mp3','preferredquality': '192'}],\n",
                "    }\n",
                "    \n",
                "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
                "        ydl.download([url])\n",
                "        \n",
                "    return audio_file\n",
                "\n",
                "def get_transcript(url):\n",
                "    if \"v=\" in url:\n",
                "        video_id = url.split(\"v=\")[1].split(\"&\")[0]\n",
                "    else:\n",
                "        print(\"‚ö†Ô∏è Invalid URL format.\")\n",
                "        return \"\"\n",
                "    \n",
                "    try:\n",
                "        transcript = YTApi.get_transcript(video_id)\n",
                "        print(\"‚úÖ Found official captions.\")\n",
                "        return \" \".join([t['text'] for t in transcript])\n",
                "    except:\n",
                "        print(\"‚ö†Ô∏è Captions unavailable. Switching to Whisper...\")\n",
                "\n",
                "    try:\n",
                "        audio_path = download_audio(url)\n",
                "        segments, _ = whisper_model.transcribe(audio_path, beam_size=1)\n",
                "        return \" \".join([seg.text for seg in segments])\n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Transcription failed: {e}\")\n",
                "        return \"\"\n",
                "\n",
                "def ingest_youtube(url):\n",
                "    print(f\"üì• Processing: {url}\")\n",
                "    text = get_transcript(url)\n",
                "    \n",
                "    if not text: return\n",
                "\n",
                "    chunks = []\n",
                "    chunk_size = 500\n",
                "    overlap = 50\n",
                "    for i in range(0, len(text), chunk_size - overlap):\n",
                "        chunks.append(text[i:i+chunk_size])\n",
                "        \n",
                "    print(f\"üß© Embedding {len(chunks)} chunks...\")\n",
                "    \n",
                "    embeddings = embed_model.encode(chunks, normalize_embeddings=True, show_progress_bar=True)\n",
                "    \n",
                "    base_id = int(time.time())\n",
                "    points = [\n",
                "        PointStruct(id=base_id + i, vector=embeddings[i].tolist(), payload={\"text\": chunks[i], \"source\": url})\n",
                "        for i in range(len(chunks))\n",
                "    ]\n",
                "    client.upsert(collection_name=COLLECTION_NAME, points=points)\n",
                "    print(\"‚úÖ Ingestion Complete.\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ---------------------------------------------------------\n",
                "# 6. 3D VISUALIZATION FUNCTION (INTERACTIVE)\n",
                "# ---------------------------------------------------------\n",
                "import plotly.io as pio\n",
                "pio.renderers.default = 'colab' # Changed back for Colab use\n",
                "\n",
                "def visualize_knowledge():\n",
                "    print(\"\\nüé® Generating Interactive 3D Brain Map...\")\n",
                "    \n",
                "    # 1. Fetch Data\n",
                "    records, _ = client.scroll(\n",
                "        collection_name=COLLECTION_NAME,\n",
                "        limit=500, \n",
                "        with_payload=True,\n",
                "        with_vectors=True\n",
                "    )\n",
                "    \n",
                "    if len(records) < 3:\n",
                "        print(\"‚ö†Ô∏è Not enough data. Ingest a video first!\")\n",
                "        return\n",
                "\n",
                "    # 2. Process Data\n",
                "    vectors = np.array([r.vector for r in records])\n",
                "    texts = [r.payload['text'][:100] + \"...\" for r in records] # Shorten text\n",
                "    \n",
                "    # 3. Reduce to 3D\n",
                "    pca = PCA(n_components=3)\n",
                "    components = pca.fit_transform(vectors)\n",
                "    \n",
                "    df = pd.DataFrame({\n",
                "        'x': components[:, 0],\n",
                "        'y': components[:, 1],\n",
                "        'z': components[:, 2],\n",
                "        'content': texts\n",
                "    })\n",
                "    \n",
                "    # 4. Create Plot\n",
                "    fig = px.scatter_3d(\n",
                "        df, x='x', y='y', z='z',\n",
                "        hover_name='content', # Shows text when you hover!\n",
                "        color='z',            # Colors points by depth\n",
                "        opacity=0.7,\n",
                "        title=f\"Mukthi Guru Brain Map ({len(records)} Memories)\",\n",
                "        template=\"plotly_dark\" # Dark mode looks better in Colab\n",
                "    )\n",
                "    \n",
                "    fig.update_traces(marker=dict(size=5))\n",
                "    fig.show() # This should now work!\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ---------------------------------------------------------\n",
                "# 7. RAG PIPELINE\n",
                "# ---------------------------------------------------------\n",
                "\n",
                "def get_guru_response(question):\n",
                "    # Retrieval\n",
                "    query_instruction = \"Represent this sentence for searching relevant passages: \"\n",
                "    q_vec = embed_model.encode(query_instruction + question, normalize_embeddings=True)\n",
                "    \n",
                "    search_result = client.query_points(collection_name=COLLECTION_NAME, query=q_vec, limit=10)\n",
                "    docs = [point.payload['text'] for point in search_result.points]\n",
                "    \n",
                "    if not docs: return \"I have no knowledge yet.\"\n",
                "\n",
                "    # Reranking\n",
                "    pairs = [[question, doc] for doc in docs]\n",
                "    scores = reranker.predict(pairs)\n",
                "    \n",
                "    top_results = []\n",
                "    for doc, score in zip(docs, scores):\n",
                "        if score > -2.0: top_results.append((doc, score))\n",
                "            \n",
                "    top_results = sorted(top_results, key=lambda x: x[1], reverse=True)[:3]\n",
                "    \n",
                "    if not top_results: return \"I am sorry, but I do not have enough knowledge on this topic yet.\"\n",
                "\n",
                "    context_text = \"\\n\\n\".join([f\"Teaching: {res[0]}\" for res in top_results])\n",
                "\n",
                "    # Generation\n",
                "    prompt_template = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
                "You are AskMukthiGuru, a compassionate spiritual guide based on the teachings of Sri Preethaji and Sri Krishnaji.\n",
                "Context: {context_text}\n",
                "User Question: {question}\n",
                "Answer:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
                "\n",
                "    if not model or not tokenizer:\n",
                "         return \"I cannot answer because the model is not loaded (Unsloth requires GPU/Colab).\"\n",
                "\n",
                "    inputs = tokenizer([prompt_template], return_tensors=\"pt\").to(DEVICE)\n",
                "    \n",
                "    outputs = model.generate(\n",
                "        **inputs, \n",
                "        max_new_tokens=512, \n",
                "        use_cache=True,\n",
                "        temperature=0.3, \n",
                "        repetition_penalty=1.1\n",
                "    )\n",
                "    \n",
                "    response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
                "    return response.split(\"assistant\")[-1].strip()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =========================================================\n",
                "# MAIN MENU\n",
                "# =========================================================\n",
                "\n",
                "print(\"\\nüïâÔ∏è AskMukthiGuru System Ready!\")\n",
                "\n",
                "while True:\n",
                "    print(\"\\n---------------- MENU ----------------\")\n",
                "    print(\"1. Ingest YouTube Video\")\n",
                "    print(\"2. üß† Visualize 3D Brain Map\")\n",
                "    print(\"3. Chat with Guru\")\n",
                "    print(\"4. Exit\")\n",
                "    choice = input(\"Enter choice (1-4): \")\n",
                "\n",
                "    if choice == '1':\n",
                "        ingest_youtube(input(\"Enter YouTube URL: \"))\n",
                "    elif choice == '2':\n",
                "        visualize_knowledge()\n",
                "    elif choice == '3':\n",
                "        print(\"\\n--- Chat Started (Type 'back' to exit) ---\")\n",
                "        while True:\n",
                "            q = input(\"You: \")\n",
                "            if q.lower() in ['back', 'exit']: break\n",
                "            print(\"Guru is thinking...\")\n",
                "            try: print(f\"\\nMukthi Guru: {get_guru_response(q)}\\n\")\n",
                "            except Exception as e: print(f\"Error: {e}\")\n",
                "    elif choice == '4':\n",
                "        print(\"Namaste.\")\n",
                "        break\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}